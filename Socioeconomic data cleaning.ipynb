{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83488ba6",
   "metadata": {
    "id": "83488ba6"
   },
   "source": [
    "# The goal of this document is to:\n",
    "\n",
    "### Merge bridge and socioeconomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c985b9c7",
   "metadata": {
    "id": "c985b9c7"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randrange\n",
    "import warnings\n",
    "import math\n",
    "from sklearn import tree\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split #from imblearn import under_sampling, over_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ec4e7",
   "metadata": {},
   "source": [
    "# Bridge Data with Demographic and socioeconomic variables \n",
    "#### 4. Retrieve relevant demographic and socioeconomic variables from the ACS 2020 5 year estimates. Map each census tract to the municipality they belong to. Aggregate these variables at municipality level and obtain summary statistics for each municipality. Mrge the summarized socioeconomic and demographic statistics to each bridge data point based on municipality\n",
    "IMPORTANT NOTE: Census tracts must stay within a county and therefore a state. They do not necessarily coincide within any other geography. For example, although some census tracts follow place boundaries, there is no rule that says they must stay within a place. This explains why some same census tracts appear in different Municipalities\n",
    "https://www.census.gov/newsroom/blogs/random-samplings/2014/07/understanding-geographic-relationships-counties-places-tracts-and-more.html<br>\n",
    "Some municipalities will have nans, as there are not enough sample points in the census tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2701abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the excel file that contains the Census Tracts and the Municipality they belong to.\n",
    "#Notice that Census Tracts in decimal format, e.g., XXXX.XX will be treated separately from Census Tracts in integer format\n",
    "CensusTractdecimals_2020_Municipality = pd.read_excel(\"CensusTracts2020_Municipalities_AlleghenyCounty.xlsx\", \n",
    "                                                      sheet_name = \"Decimals\")\n",
    "CensusTractintegers_2020_Municipality = pd.read_excel(\"CensusTracts2020_Municipalities_AlleghenyCounty.xlsx\", \n",
    "                                                      sheet_name = \"Integers\")\n",
    "#Convert the census tract columns to string characters\n",
    "CensusTractdecimals_2020_Municipality[\"CensusTract\"] = CensusTractdecimals_2020_Municipality[\"CensusTract\"].astype(str)\n",
    "CensusTractintegers_2020_Municipality[\"CensusTract\"] = CensusTractintegers_2020_Municipality[\"CensusTract\"].astype(str)\n",
    "\n",
    "#Create a dictionary, in which the keys are the census tracts and the values are the municipalities they belong to\n",
    "CensusTracts_to_Municipality_dict = dict(zip(CensusTractintegers_2020_Municipality.CensusTract, \n",
    "                                             CensusTractintegers_2020_Municipality.Municipality))\n",
    "CensusTracts_to_Municipality_dict.update(dict(zip(CensusTractdecimals_2020_Municipality.CensusTract, \n",
    "                                                  CensusTractdecimals_2020_Municipality.Municipality)))\n",
    "#Convert the keys of the dictionary to string characters\n",
    "CensusTracts_to_Municipality_dict = {str(key): str(value) for key, value in CensusTracts_to_Municipality_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844475e",
   "metadata": {},
   "source": [
    "#### Race\n",
    "#### Information was retrieved from ACS 2020 5-year estimates. This dataframe describes the population composition in terms of race for each census tract. Data will be aggregated at the municipality level. Notice that some census tracts may not contain data points. This is due to these reasons: 1) the number of sample cases is too small or 2) no sample observations available. In this case, nans are ignored when aggregating values at the municipality level. Value were aggregate by adding all census tracts statistics or averaging all census tracts statistics.  The dataframe at municipality level contains absolute estimates and percentages (with respect to the total population) of race composition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2922afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the census data \n",
    "race_df = pd.read_excel(\"Total_Population_Race_2020.xlsx\")\n",
    "\n",
    "#Retrieve the census tract and save it as a string\n",
    "race_df[\"GEO_ID_CensusTract\"] = race_df.Geography.str[14:].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#Add decimal points\n",
    "race_df[\"CensusTract(decimal format)\"] = race_df[\"GEO_ID_CensusTract\"].str[:-2]+'.'+race_df[\"GEO_ID_CensusTract\"].str[-2:]\n",
    "\n",
    "#Replace the .00 to \"\"\n",
    "race_df[\"CensusTract(decimal format)\"] = race_df[\"CensusTract(decimal format)\"].astype(str)\n",
    "race_df[\"CensusTract(decimal format)\"] = race_df[\"CensusTract(decimal format)\"].str.replace(\".00\", \"\", regex=False)\n",
    "\n",
    "#Create a new column that indicates the Municipality to which each row of census data frame belongs to\n",
    "race_df['Municipality'] = race_df[\"CensusTract(decimal format)\"].map(CensusTracts_to_Municipality_dict)\n",
    "\n",
    "#The following df contains the number of inhabitants in each municipality according to their race\n",
    "Municipality_race_df = pd.pivot_table(race_df, values=['Total population', \n",
    "                                                    \"Hispanic or Latino (of any race)\", \n",
    "                                                    \"White alone\", \n",
    "                                                    \"Black or African American alone\", \n",
    "                                                    \"American Indian and Alaska Native alone\", \n",
    "                                                    \"Asian alone\", \n",
    "                                                    \"Native Hawaiian and Other Pacific Islander alone\",\n",
    "                                                    \"Some other race alone\", \n",
    "                                                    \"Two or more races\"], \n",
    "                                   index=['Municipality'],\n",
    "                                   aggfunc={'Total population': np.sum,\n",
    "                                            \"Hispanic or Latino (of any race)\" : np.sum, \n",
    "                                             \"White alone\" : np.sum, \n",
    "                                             \"Black or African American alone\": np.sum, \n",
    "                                             \"American Indian and Alaska Native alone\": np.sum, \n",
    "                                             \"Asian alone\": np.sum, \n",
    "                                             \"Native Hawaiian and Other Pacific Islander alone\": np.sum,\n",
    "                                             \"Some other race alone\": np.sum, \n",
    "                                             \"Two or more races\": np.sum})\n",
    "\n",
    "#find percentages\n",
    "Municipality_race_df[\"%Hispanic\"] = (Municipality_race_df[\"Hispanic or Latino (of any race)\"] / \n",
    "                                     Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%White alone\"] = (Municipality_race_df[\"White alone\"] / \n",
    "                                        Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%Black or African American alone\"] = (Municipality_race_df[\"Black or African American alone\"] / \n",
    "                                                            Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%American Indian and Alaska Native alone\"] = (\n",
    "    Municipality_race_df[\"American Indian and Alaska Native alone\"] / Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%Asian alone\"] = (Municipality_race_df[\"Asian alone\"] / \n",
    "                                        Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%Native Hawaiian and Other Pacific Islander alone\"] = (\n",
    "    Municipality_race_df[\"Native Hawaiian and Other Pacific Islander alone\"] / \n",
    "    Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%Some other race alone\"] = (Municipality_race_df[\"Some other race alone\"] /\n",
    "                                                  Municipality_race_df[\"Total population\"]) * 100\n",
    "Municipality_race_df[\"%Two or more races\"] = (Municipality_race_df[\"Two or more races\"] / \n",
    "                                              Municipality_race_df[\"Total population\"]) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43159e",
   "metadata": {},
   "source": [
    "#### Economic characteristics\n",
    "#### Information was retrieved from ACS 2020 5-year estimates. This dataframe provides information regarding the total number of civilian labor force, unemployment rate among civilian labor force, mean household income, total number of workers, the number of workers according to their of means of transportation to work. Data will be aggregated at the municipality level. Notice that some census tracts may not contain data points. This is due to these reasons: 1) the number of sample cases is too small or 2) no sample observations available. In this case, nans are ignored when aggregating values at the municipality level. Value were aggregate by adding all census tracts statistics or averaging all census tracts statistics.  The dataframe at municipality level contains absolute estimates and percentages (with respect to the total number of workers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b51021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the census data \n",
    "econ_characs_df = pd.read_excel(\"Econ_Characs_2020_data.xlsx\")\n",
    "\n",
    "#Retrieve the census tract and save it as a string\n",
    "econ_characs_df[\"GEO_ID_CensusTract\"] = econ_characs_df.Geography.str[14:].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#Add decimal points\n",
    "econ_characs_df[\"CensusTract(decimal format)\"] = econ_characs_df[\"GEO_ID_CensusTract\"].str[:-2]+'.'+econ_characs_df[\"GEO_ID_CensusTract\"].str[-2:]\n",
    "\n",
    "#Replace the .00 to \"\"\n",
    "econ_characs_df[\"CensusTract(decimal format)\"] = econ_characs_df[\"CensusTract(decimal format)\"].astype(str)\n",
    "econ_characs_df[\"CensusTract(decimal format)\"] = econ_characs_df[\"CensusTract(decimal format)\"].str.replace(\".00\", \"\", regex=False)\n",
    "\n",
    "#Create a new column that indicates the Municipality to which each row of census data frame belongs to\n",
    "econ_characs_df['Municipality'] = econ_characs_df[\"CensusTract(decimal format)\"].map(CensusTracts_to_Municipality_dict)\n",
    "\n",
    "#The following df contains the average unemployment rate, household income in each municipality\n",
    "Municipality_economic_characs_df = pd.pivot_table(econ_characs_df, values=['Total civilian labor force',\n",
    "                                                                          'Unemployment Rate among civilian labor force',\n",
    "                                                                           'Mean household income (dollars)',\n",
    "                                                                           'Total number workers 16 years and over',\n",
    "                                                                           'Total workers that commute with car, truck, or van  drove alone',\n",
    "                                                                           'Total workers that commute with car, truck, or van  carpooled',\n",
    "                                                                           'Total workers that commute with public transportation (excluding taxicab)',\n",
    "                                                                           'Total workers that walked',\n",
    "                                                                           'Total workers that commute by other means',\n",
    "                                                                            'Total workers that worked from home'], \n",
    "                                                                   index=['Municipality'],\n",
    "                                                                   aggfunc={'Total civilian labor force': np.sum,\n",
    "                                                                            'Unemployment Rate among civilian labor force' : np.mean,\n",
    "                                                                            'Mean household income (dollars)' : np.mean, \n",
    "                                                                           'Total number workers 16 years and over': np.sum,\n",
    "                                                                           'Total workers that commute with car, truck, or van  drove alone': np.sum,\n",
    "                                                                           'Total workers that commute with car, truck, or van  carpooled': np.sum,\n",
    "                                                                           'Total workers that commute with public transportation (excluding taxicab)': np.sum,\n",
    "                                                                           'Total workers that walked': np.sum,\n",
    "                                                                           'Total workers that commute by other means': np.sum,\n",
    "                                                                            'Total workers that worked from home': np.sum})\n",
    "\n",
    "#Find percentages\n",
    "econ_characs_df[\"%Total workers that commute with car, truck, or van  drove alone\"] = (econ_characs_df[\"Total workers that commute with car, truck, or van  drove alone\"] / econ_characs_df[\"Total number workers 16 years and over\"]) * 100\n",
    "econ_characs_df[\"%Total workers that commute with car, truck, or van  carpooled\"] = (econ_characs_df[\"Total workers that commute with car, truck, or van  carpooled\"] / econ_characs_df[\"Total number workers 16 years and over\"]) * 100\n",
    "econ_characs_df[\"%Total workers that commute with public transportation (excluding taxicab)\"] = (econ_characs_df[\"Total workers that commute with public transportation (excluding taxicab)\"] / econ_characs_df[\"Total number workers 16 years and over\"]) * 100\n",
    "econ_characs_df[\"%Total workers that walked\"] = (econ_characs_df[\"Total workers that walked\"] / econ_characs_df[\"Total number workers 16 years and over\"]) * 100\n",
    "econ_characs_df[\"%Total workers that commute by other means\"] = (econ_characs_df[\"Total workers that commute by other means\"] / econ_characs_df[\"Total number workers 16 years and over\"]) * 100\n",
    "econ_characs_df[\"%Total workers that worked from home\"] = (econ_characs_df[\"Total workers that worked from home\"] / econ_characs_df[\"Total number workers 16 years and over\"]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f48ff3",
   "metadata": {},
   "source": [
    "#### Poverty information\n",
    "#### Information was retrieved from ACS 2020 5-year estimates. This dataframe provides information regarding the total number of inhabitants living in poverty, and the number of inhabitants living below the poverty status at each census tract. Data will be aggregated at the municipality level. Notice that some census tracts may not contain data points. This is due to these reasons: 1) the number of sample cases is too small or 2) no sample observations available. In this case, nans are ignored when aggregating values at the municipality level. Value were aggregate by adding all census tracts statistics or averaging all census tracts statistics.  The dataframe at municipality level contains absolute estimates and percentages (with respect to the total population living in poverty status) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51eb04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the census data \n",
    "poverty_status_df = pd.read_excel(\"PovertyStatus_data_2020.xlsx\")\n",
    "\n",
    "#Retrieve the census tract and save it as a string\n",
    "poverty_status_df[\"GEO_ID_CensusTract\"] = poverty_status_df.Geography.str[14:].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#Add decimal points\n",
    "poverty_status_df[\"CensusTract(decimal format)\"] = poverty_status_df[\"GEO_ID_CensusTract\"].str[:-2]+'.'+poverty_status_df[\"GEO_ID_CensusTract\"].str[-2:]\n",
    "\n",
    "#Replace the .00 to \"\"\n",
    "poverty_status_df[\"CensusTract(decimal format)\"] = poverty_status_df[\"CensusTract(decimal format)\"].astype(str)\n",
    "poverty_status_df[\"CensusTract(decimal format)\"] = poverty_status_df[\"CensusTract(decimal format)\"].str.replace(\".00\", \"\", regex=False)\n",
    "\n",
    "#Create a new column that indicates the Municipality to which each row of census data frame belongs to\n",
    "poverty_status_df['Municipality'] = poverty_status_df[\"CensusTract(decimal format)\"].map(CensusTracts_to_Municipality_dict)\n",
    "#The following df contains number living in poverty and the number of people living below the poverty level\n",
    "Municipality_poverty_df = pd.pivot_table(poverty_status_df, values=['Total population for whom poverty status is determined',\n",
    "                                                                    'Total population for whom poverty status is determined (Below poverty level)'], \n",
    "                                                                   index=['Municipality'],\n",
    "                                                                   aggfunc={'Total population for whom poverty status is determined' : np.sum,\n",
    "                                                                            'Total population for whom poverty status is determined (Below poverty level)': np.sum})\n",
    "\n",
    "Municipality_poverty_df[\"%Total population for whom poverty status is determined (Below poverty level)\"] = (\n",
    "    Municipality_poverty_df[\"Total population for whom poverty status is determined (Below poverty level)\"]/\n",
    "    Municipality_poverty_df[\"Total population for whom poverty status is determined\"])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e3dd3",
   "metadata": {},
   "source": [
    "#### Educational attainment information\n",
    "#### Information was retrieved from ACS 2020 5-year estimates. This dataframe provides information regarding the total number of households, the total population older than 25 years, and the population (older than 25 years old) with less than 9th grade. Data will be aggregated at the municipality level. Notice that some census tracts may not contain data points. This is due to these reasons: 1) the number of sample cases is too small or 2) no sample observations available. In this case, nans are ignored when aggregating values at the municipality level. Value were aggregate by adding all census tracts statistics or averaging all census tracts statistics.  The dataframe at municipality level contains absolute estimates and percentages (with respect to the total population older than 25 years) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225dc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the census data \n",
    "educational_attainment_df = pd.read_excel(\"EducationalAttainment_2020_data.xlsx\")\n",
    "\n",
    "#Retrieve the census tract and save it as a string\n",
    "educational_attainment_df[\"GEO_ID_CensusTract\"] = educational_attainment_df.Geography.str[14:].astype(str).str.lstrip(\"0\")\n",
    "\n",
    "#Add decimal points\n",
    "educational_attainment_df[\"CensusTract(decimal format)\"] = educational_attainment_df[\"GEO_ID_CensusTract\"].str[:-2]+'.'+educational_attainment_df[\"GEO_ID_CensusTract\"].str[-2:]\n",
    "\n",
    "#Replace the .00 to \"\"\n",
    "educational_attainment_df[\"CensusTract(decimal format)\"] = educational_attainment_df[\"CensusTract(decimal format)\"].astype(str)\n",
    "educational_attainment_df[\"CensusTract(decimal format)\"] = educational_attainment_df[\"CensusTract(decimal format)\"].str.replace(\".00\", \"\", regex=False)\n",
    "\n",
    "#Create a new column that indicates the Municipality to which each row of census data frame belongs to\n",
    "educational_attainment_df['Municipality'] = educational_attainment_df[\"CensusTract(decimal format)\"].map(CensusTracts_to_Municipality_dict)\n",
    "#The following df contains the number of households, population of 25 years and over, and population with less than 9th grade completed\n",
    "Municipality_educational_attainment_df = pd.pivot_table(educational_attainment_df, values=['Total number households',\n",
    "                                                                    'Total population 25 years and over',\n",
    "                                                                    'Total population 25 years and over with less than 9th grade'], \n",
    "                                                                   index=['Municipality'],\n",
    "                                                                   aggfunc={'Total number households' : np.sum,\n",
    "                                                                            'Total population 25 years and over': np.sum,\n",
    "                                                                           'Total population 25 years and over with less than 9th grade' : np.sum})\n",
    "\n",
    "\n",
    "#Find percentages\n",
    "Municipality_educational_attainment_df[\"%Total population 25 years and over with less than 9th grade\"] = (Municipality_educational_attainment_df[\"Total population 25 years and over with less than 9th grade\"]/Municipality_educational_attainment_df[\"Total population 25 years and over\"])*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc1ea0",
   "metadata": {},
   "source": [
    "#### Merge the socioeconomic and demographic statistics of municipalities to the bridge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ada261",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6c44cd90919f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Read the file that contains the PA22 - 22 csv file with the municipality of Allegheny county where every bridge belongs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mBridges_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#Join the 4 different df that contains demographic information about municipalities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m Bridges_Municipalities_Demographics_df = Bridges_df.merge(right = Municipality_educational_attainment_df, \n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df.csv'"
     ]
    }
   ],
   "source": [
    "#Read the file that contains the PA22 - 22 csv file with the municipality of Allegheny county where every bridge belongs to\n",
    "Bridges_df = pd.read_csv(\"df.csv\")\n",
    "#Join the 4 different df that contains demographic information about municipalities \n",
    "\n",
    "Bridges_Municipalities_Demographics_df = Bridges_df.merge(right = Municipality_educational_attainment_df, \n",
    "                                                       how = \"left\", \n",
    "                                                       left_on = \"Municipality\", \n",
    "                                                       right_on = \"Municipality\")\n",
    "\n",
    "Bridges_Municipalities_Demographics_df = Bridges_Municipalities_Demographics_df.merge(right = Municipality_poverty_df, \n",
    "                                                       how = \"left\", \n",
    "                                                       left_on = \"Municipality\", \n",
    "                                                       right_on = \"Municipality\")\n",
    "\n",
    "Bridges_Municipalities_Demographics_df = Bridges_Municipalities_Demographics_df.merge(right = Municipality_economic_characs_df, \n",
    "                                                       how = \"left\", \n",
    "                                                       left_on = \"Municipality\", \n",
    "                                                       right_on = \"Municipality\")\n",
    "\n",
    "Bridges_Municipalities_Demographics_df = Bridges_Municipalities_Demographics_df.merge(right = Municipality_race_df, \n",
    "                                                       how = \"left\", \n",
    "                                                       left_on = \"Municipality\", \n",
    "                                                       right_on = \"Municipality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This dataframe contains socioeconomic and demographic statistics and characteristics of each bridge. Lets merge this df\n",
    "## with the df that has already been prepared\n",
    "Bridges_Municipalities_Demographics_df = Bridges_Municipalities_Demographics_df[[\"Original_row_number\",\"Municipality\",\n",
    "\"Total number households\",\n",
    "\"Total population 25 years and over\",\n",
    "\"Total population 25 years and over with less than 9th grade\",\n",
    "\"%Total population 25 years and over with less than 9th grade\",\n",
    "\"Total population for whom poverty status is determined\",\n",
    "\"Total population for whom poverty status is determined (Below poverty level)\",\n",
    "\"%Total population for whom poverty status is determined (Below poverty level)\",\n",
    "\"Mean household income (dollars)\",\n",
    "\"Total civilian labor force\",\n",
    "\"Total number workers 16 years and over\",\n",
    "\"Total workers that commute by other means\",\n",
    "\"Total workers that commute with car, truck, or van  carpooled\",\n",
    "\"Total workers that commute with car, truck, or van  drove alone\",\n",
    "\"Total workers that commute with public transportation (excluding taxicab)\",\n",
    "\"Total workers that walked\",\n",
    "\"Total workers that worked from home\",\n",
    "\"Unemployment Rate among civilian labor force\",\n",
    "\"American Indian and Alaska Native alone\",\n",
    "\"Asian alone\",\n",
    "\"Black or African American alone\",\n",
    "\"Hispanic or Latino (of any race)\",\n",
    "\"Native Hawaiian and Other Pacific Islander alone\",\n",
    "\"Some other race alone\",\n",
    "\"Total population\",\n",
    "\"Two or more races\",\n",
    "\"White alone\",\n",
    "\"%Hispanic\",\n",
    "\"%White alone\",\n",
    "\"%Black or African American alone\",\n",
    "\"%American Indian and Alaska Native alone\",\n",
    "\"%Asian alone\",\n",
    "\"%Native Hawaiian and Other Pacific Islander alone\",\n",
    "\"%Some other race alone\",\n",
    "\"%Two or more races\"]]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df2 = df.merge(right = Bridges_Municipalities_Demographics_df,\n",
    "             how = \"inner\", \n",
    "             left_on = \"index\", \n",
    "             right_on = \"Original_row_number\")\n",
    "\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70e089",
   "metadata": {},
   "source": [
    "## Normalization of the socioeconomic and demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Structure_Kind_Aluminum'] #confirming dummy variabkes are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71115ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_var=df.columns[90:] #include only demographic and socio econmoic data\n",
    "df_norm=df2.copy()\n",
    "df_norm = normalize(df_norm, continous_var) #normalize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for var in list(df_norm.columns):   #Checks for any columns remaining that are not in the correct format (numerical)\n",
    "    print(var, df_norm[var].dtypes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4104e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#municipality name must be dropped for classification modelb because it is in object format\n",
    "df_norm.drop(columns = 'Municipality', inplace = True)\n",
    "#df_norm['Municipality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for var in list(df_norm.columns):   #Checks for any columns remaining that are not in the correct format (numerical)\n",
    "    print(var, df_norm[var].dtypes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.dropna(inplace=True)  #remove NAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv = ('df_norm.csv') #saving locally"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
